{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Modern filtering algorithms take advantage of the generative model paradigm:\n",
    "\n",
    "1. Estimate the signal at T+1 and its error distribution\n",
    "2. Adjust the estimate given sensor data and its error distribution\n",
    "3. Repeat\n",
    "\n",
    "The most general of these algorithms is the **Bayes Filter**. In context of robotics, the signal estimate & error distribution is our *belief* estimate. Algorithmically it is as follows:\n",
    "\n",
    "* **bayes_filter**($bel(x_{t-1}), u_t, z_t)$:\n",
    "  * for all $x_t \\,$ do\n",
    "    * $ \\overline{bel}(x_t) = \\int p(x_t \\: | \\: u_t, x_{t-1}) \\cdot bel(x_{t-1}) dx_{t-1} $\n",
    "    * $ bel(x_t) = \\eta p(z_t \\: | \\: x_t) \\cdot \\overline{bel}(x_t) $\n",
    "  * return $ bel(x_t) $\n",
    "\n",
    "As you can see, this is a recursive calculation: in order to calculate $bel(x_t)$, we need to calculate all $bel(x_{0:t-1})$.\n",
    "\n",
    "Note the order we're calculating the prior and posterior beliefs. The prior, or *prediction update*, is generating an estimate of how we expect the environment state *x* to evolve given an action *u*. The posterior, or *measurement update*, is generated using *Bayes' Rule* of the distribution of the sensor measurement given the distribution of current states and our belief in the present state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivation of the Bayes Filter\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Markov Assumption\n",
    "Simply put, this algorithm (and all probabilistic filters) assume that the state $x_t$ is *complete*, thus both past and future data are dependent. Think along the same lines as a *Minkowski diagram*, but treat position and velocity as random variables: to arrive at a certain point within a confidence interval, there is a limited number of positions in the universe to start from; likewise, there is an equally limited number of positions to go to from the point at <X, t=0>.\n",
    "\n",
    "This assumption, however, is flawed... In actuality, we will be dealing with incomplete states constantly, for example human motion (people can arbitrarily change speed and acceleration), inaccuracies in map data, and software-driven control systems (because control actions are not arbitrary when there is a goal in mind).\n",
    "\n",
    "Still, hope is not lost. The Bayes Filter has been demonstrated to be quite robust against violations of the Markov Assumption. This is typically driven by ensuring/treating unmodeled state variables having near-random effects (that is, treating it more like system/plant noise & bias). Even still, the incompleteness of our state modeling is to our benefit: it reduces the overall computational complexity (fewer dimensions to integrate over)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation & Computation\n",
    "Bayes Filters represent a whole family of filters, each with differing levels of accuracy/approximation, efficiency, and ease of implementation. Note that exact techniques for calculating beliefs exist for only highly specialized cases -- for general problems, the beliefs will be approximated. The trade space is:\n",
    "\n",
    "* **Computational Efficiency** - Some are polynomial time w.r.t. state-space dimensionality, while others are exponential or *any-time*. These will vary with ...\n",
    "* **Accuracy of the Approximation** - Some will approximate a wider range of distributions than others; they may be limited to unimodal Gaussian distributions or allow for multimodal.\n",
    "* **Ease of Implementation** - Remember, implementing a Kalman Filter is easy. *Deriving* the filter is the difficult part. Some filters will exhibit *vise-versa* characteristics!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
